# ğŸ¤– FastAPI Chatbot API

[![Docker Pulls](https://img.shields.io/docker/pulls/ataur077/faq-bot.svg)](https://hub.docker.com/r/ataur077/faq-bot)

A lightweight and efficient chatbot API built using **FastAPI** and Dockerized for easy deployment. This project demonstrates a simple RESTful API that accepts user input and returns chatbot responses via a custom logic module.

---

## ğŸš€ Features

- ğŸ”¥ Fast and asynchronous REST API with FastAPI
- â™»ï¸ CORS enabled for cross-origin communication
- ğŸ“¦ Dockerized for production-ready deployment
- ğŸ§  Modular chatbot logic (customizable via `chatbot.py`)

---

## ğŸ“ Project Structure
```
fastapi-chatbot/
â”œâ”€â”€ app.py # Main FastAPI app
â”œâ”€â”€ chatbot.py # Chat logic (stream_graph_updates function)
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ Dockerfile # Docker configuration
â””â”€â”€ README.md # Project documentation
```

---

## ğŸ› ï¸ Setup Instructions

### ğŸ”§ Prerequisites

- Python 3.11+
- Docker

### ğŸ Run Locally (Without Docker)

1. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```
Start the API
```
uvicorn app:app --reload
```
Visit the interactive docs:
`http://localhost:8000/docs`

### ğŸ³ Run with Docker (Locally)
Build the Docker image
```
docker build -t faq-bot .
```
Run the container
```
docker run -d -p 8000:8000 \
  --env GEMINI_KEY=your_real_gemini_api_key \
  ataur077/faq-bot
```

Access the API at:
`http://localhost:8000`
API Docs: `http://localhost:8000/docs`

### ğŸ³ Run from DockerHub (Public Image)
You can pull and run this app directly from DockerHub:
```
docker pull ataur077/faq-bot:latest
docker run -d -p 8000:8000 \
  --env GEMINI_KEY=your_real_gemini_api_key \
  ataur077/faq-bot
```
Then visit: http://localhost:8000/docs

## ğŸ“¬ API Endpoints
- `GET /
Returns a status message.`
    ```
    { "message": "API is running!" }
    ```

- `POST /chat
Send user input and get chatbot response.`

    - Request Body
    ```
    {
    "user_input": "Hello, chatbot!"
    }
    ```

    - Response
    ```
    {
    "response": "Hi there! How can I help you today?"
    }
    ```

## ğŸ§  Customize the Chatbot
All chatbot logic is located in chatbot.py. You can define the stream_graph_updates(user_input: str) function to return responses based on any rule-based, ML-based, or LLM-based logic.

## ğŸ“„ License
This project is open-source and free to use under the [MIT License](./LICENSE.md).

